{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "  Welcome to MONPA: Multi-Objective NER POS Annotator for Chinese\n",
      "+---------------------------------------------------------------------+\n",
      "已找到 model檔。Found model file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eeb02\\.virtualenvs\\HW2-PfLazmZH\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from gensim.models import word2vec, Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import gensim\n",
    "import monpa\n",
    "import csv\n",
    "from monpa import utils\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('./terms_data/mid_news_OK.csv', delimiter=',', encoding='utf-8')\n",
    "bbs_df = pd.read_csv('./terms_data/mid_bbs_OK.csv', delimiter=',', encoding='utf-8')\n",
    "forum_df = pd.read_csv('./terms_data/mid_forum_OK.csv', delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_time</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>財政部 內政部 一站式 服務 動產 移轉 登記 搞定 避免 民眾 辦理 動產 買賣 移轉 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>IMF 美元 全球 外匯 儲備 比重 新高 週二 31 國際貨幣組織 公布 IMF 數據 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>騰訊集團 34億 美元 收購 環球 音樂 10 股權 外電 報導 騰訊集團 0700 HK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>加幣 漲幅 勇冠 10 瑞信 央行 政策 明年 主要 風險 週二 31 受到 中國 強勁 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>股盤 收低 中央社 台北 2020年 1月 1日 歐洲 股市 今年 最後 交易日 交易 清...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230605</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>友達 ❷❺ 元以 蘇起 不知 多少 老是 說話</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230606</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>長期 投資人 ETF 超額 報酬 建議 巴菲特 2013年 股東信 提出 建議 一般人 不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230607</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>美國 台積電 美國 設廠 不會 影響 美國 台灣 安全 承諾 晶片 中國 打掉 台灣 之後...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230608</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>快笑死 根本 指標 AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230609</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉 預測 短期 一日 行情 甚麼 意...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_time                                            content\n",
       "0        2020-01-01   財政部 內政部 一站式 服務 動產 移轉 登記 搞定 避免 民眾 辦理 動產 買賣 移轉 ...\n",
       "1        2020-01-01   IMF 美元 全球 外匯 儲備 比重 新高 週二 31 國際貨幣組織 公布 IMF 數據 ...\n",
       "2        2020-01-01   騰訊集團 34億 美元 收購 環球 音樂 10 股權 外電 報導 騰訊集團 0700 HK...\n",
       "3        2020-01-01   加幣 漲幅 勇冠 10 瑞信 央行 政策 明年 主要 風險 週二 31 受到 中國 強勁 ...\n",
       "4        2020-01-01   股盤 收低 中央社 台北 2020年 1月 1日 歐洲 股市 今年 最後 交易日 交易 清...\n",
       "...             ...                                                ...\n",
       "1230605  2023-03-21                           友達 ❷❺ 元以 蘇起 不知 多少 老是 說話\n",
       "1230606  2023-03-21   長期 投資人 ETF 超額 報酬 建議 巴菲特 2013年 股東信 提出 建議 一般人 不...\n",
       "1230607  2023-03-21   美國 台積電 美國 設廠 不會 影響 美國 台灣 安全 承諾 晶片 中國 打掉 台灣 之後...\n",
       "1230608  2023-03-21             快笑死 根本 指標 AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉\n",
       "1230609  2023-03-21   AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉 預測 短期 一日 行情 甚麼 意...\n",
       "\n",
       "[1230610 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_df = pd.concat([news_df, bbs_df, forum_df], ignore_index=True)\n",
    "term_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del news_df, bbs_df, forum_df\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 轉為 List of str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitWord(x):\n",
    "    try:\n",
    "        x = x.split(' ')\n",
    "    except:\n",
    "        x = str(x).split(' ')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [財政部, 內政部, 一站式, 服務, 動產, 移轉, 登記, 搞定, 避免, 民眾, 辦理...\n",
       "1    [IMF, 美元, 全球, 外匯, 儲備, 比重, 新高, 週二, 31, 國際貨幣組織, ...\n",
       "2    [騰訊集團, 34億, 美元, 收購, 環球, 音樂, 10, 股權, 外電, 報導, 騰訊...\n",
       "3    [加幣, 漲幅, 勇冠, 10, 瑞信, 央行, 政策, 明年, 主要, 風險, 週二, 3...\n",
       "4    [股盤, 收低, 中央社, 台北, 2020年, 1月, 1日, 歐洲, 股市, 今年, 最...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_df['content'] = term_df['content'].apply( lambda x: splitWord(x))\n",
    "term_df['content'].apply( lambda x: x.pop(0))\n",
    "term_df['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_sentences[7312]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU state: Available\n",
      "GPU total memory: 11263.75 MB\n",
      "Reserve for excution: 0.00 MB\n",
      "Execution allocated: 0.00 MB\n",
      "Free memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "monpa.use_gpu(True)\n",
    "\n",
    "def print_gpu_memory():\n",
    "    gpu_state = torch.cuda.is_available()\n",
    "    total_m = torch.cuda.get_device_properties(0).total_memory/(1024**2)\n",
    "    reserved_m = torch.cuda.memory_reserved(0)/(1024**2)\n",
    "    allocated_m = torch.cuda.memory_allocated(0)/(1024**2)\n",
    "    free_m = reserved_m-allocated_m\n",
    "    \n",
    "    print('GPU state: {:s}\\nGPU total memory: {:.2f} MB\\nReserve for excution: {:.2f} MB\\nExecution allocated: {:.2f} MB\\nFree memory: {:.2f} MB'\\\n",
    "        .format('Available' if gpu_state else 'None', total_m, reserved_m, allocated_m, free_m))\n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut into list of list of words\n",
    "def word_Tokenize(contents: list) -> list:    \n",
    "    term_list = list()\n",
    "    step = 1  # 設定幾篇文章合併\n",
    "    for index in tqdm(range(0, len(contents), step), desc=\"Wordcutting process: \"):\n",
    "        if  index % 10000 == 0:\n",
    "            print_gpu_memory()\n",
    "            # Clear gpu cache\n",
    "            # torch.cuda.empty_cache()           \n",
    "        # sentence_list = list()\n",
    "        # for i in range(step):   # 將多篇文章合併  \n",
    "        #     if index+i >= len(contents):      \n",
    "        #         break;    \n",
    "        sentence_list = utils.short_sentence(contents[index])\n",
    "        \n",
    "        result_cut = monpa.cut_batch(sentence_list) #斷詞 GPU加速method\n",
    "        # print(result_cut)\n",
    "        tmp_list = list()\n",
    "        for terms in result_cut:            \n",
    "            if len(terms) > 0: \n",
    "                term = terms[0].strip() #去除前後多餘空白\n",
    "                # print(term)\n",
    "                #若詞長>1 (排除標點符號、單字)，排除英數字\n",
    "                if(len(term)>1 and len(term)<=8) and (not term.isdigit()):\n",
    "                    tmp_list.append(term)   \n",
    "        \n",
    "        if len(tmp_list) > 2:\n",
    "            term_list.append(tmp_list)                     \n",
    "    \n",
    "    return term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU state: Available\n",
      "GPU total memory: 11263.75 MB\n",
      "Reserve for excution: 0.00 MB\n",
      "Execution allocated: 0.00 MB\n",
      "Free memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory()\n",
    "# term_list = raw_sentences\n",
    "term_list = term_df['content']\n",
    "# term_list = word_Tokenize(raw_sentences)  # ~3hr40min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMF',\n",
       " '美元',\n",
       " '全球',\n",
       " '外匯',\n",
       " '儲備',\n",
       " '比重',\n",
       " '新高',\n",
       " '週二',\n",
       " '31',\n",
       " '國際貨幣組織',\n",
       " '公布',\n",
       " 'IMF',\n",
       " '數據',\n",
       " '顯示',\n",
       " '今年',\n",
       " '美元',\n",
       " '全球',\n",
       " '外匯',\n",
       " '儲備',\n",
       " '占比',\n",
       " '水平',\n",
       " '日圓',\n",
       " '佔比',\n",
       " '持續',\n",
       " '升至',\n",
       " '20',\n",
       " 'BR',\n",
       " '根據',\n",
       " 'IMF',\n",
       " '數據',\n",
       " '美元',\n",
       " '持有',\n",
       " '儲備',\n",
       " '金額',\n",
       " '第',\n",
       " '3',\n",
       " '季',\n",
       " '達到',\n",
       " '6.75',\n",
       " '美元',\n",
       " '整體',\n",
       " '占比',\n",
       " '61.78',\n",
       " '低於',\n",
       " '第',\n",
       " '2',\n",
       " '季',\n",
       " '6.79',\n",
       " '美元',\n",
       " '占比',\n",
       " '高於',\n",
       " '上季',\n",
       " '61.49',\n",
       " '2018',\n",
       " '以來',\n",
       " '占比',\n",
       " 'BR',\n",
       " '另外',\n",
       " '日圓',\n",
       " '第',\n",
       " '3',\n",
       " '全球',\n",
       " '外匯',\n",
       " '儲備',\n",
       " '佔比',\n",
       " '上升',\n",
       " '5.6',\n",
       " '高於',\n",
       " '上季',\n",
       " '5.41',\n",
       " '2000',\n",
       " '年',\n",
       " '新高',\n",
       " '人民幣',\n",
       " '上升',\n",
       " '2.01',\n",
       " '2016',\n",
       " '年',\n",
       " '第',\n",
       " '4',\n",
       " '季',\n",
       " '以來',\n",
       " '水平',\n",
       " 'BR',\n",
       " '儘管',\n",
       " '美元',\n",
       " '日圓',\n",
       " '人民幣',\n",
       " '外匯',\n",
       " '儲備',\n",
       " '占比',\n",
       " '上季',\n",
       " '增加',\n",
       " '歐元',\n",
       " '占比',\n",
       " '下降',\n",
       " '20.0',\n",
       " '2017',\n",
       " '年',\n",
       " '第',\n",
       " '3',\n",
       " '季',\n",
       " '以來',\n",
       " '英鎊',\n",
       " '占比',\n",
       " '下降',\n",
       " '4.43',\n",
       " 'BR',\n",
       " '報告',\n",
       " '看來',\n",
       " '美元',\n",
       " '依舊',\n",
       " '位居',\n",
       " '全球',\n",
       " '主要',\n",
       " '儲備',\n",
       " '貨幣',\n",
       " '寶座',\n",
       " '近年',\n",
       " '中國',\n",
       " '俄羅斯',\n",
       " '央行',\n",
       " '努力',\n",
       " '削弱',\n",
       " '美元',\n",
       " '霸權',\n",
       " '地位',\n",
       " '美元',\n",
       " '國家',\n",
       " '外匯',\n",
       " '儲備',\n",
       " '分散',\n",
       " '出來',\n",
       " 'BR',\n",
       " 'Tempus',\n",
       " '交易',\n",
       " '部門',\n",
       " '副總裁',\n",
       " 'John',\n",
       " 'Doyle',\n",
       " '表示',\n",
       " '確實',\n",
       " '認為',\n",
       " '美元',\n",
       " '部分',\n",
       " '權力',\n",
       " '逐漸',\n",
       " '消退',\n",
       " '全球',\n",
       " '央行',\n",
       " '朝向',\n",
       " '多元化',\n",
       " '發展',\n",
       " '長期',\n",
       " '美元',\n",
       " '依舊',\n",
       " '解決',\n",
       " '國際',\n",
       " '貿易',\n",
       " '主要',\n",
       " '貨幣',\n",
       " '因此',\n",
       " '持續',\n",
       " '佔據',\n",
       " '大部分',\n",
       " '外匯',\n",
       " '儲備']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(term_list)\n",
    "term_list[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model configs\n",
    "import random\n",
    "config = {\n",
    "    'vector_size': 250,\n",
    "    'window': 6,\n",
    "    'min_count': 10,\n",
    "    'n_worker': 4,\n",
    "    'epochs': 10,\n",
    "    'seed': random.seed(7311),     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec Training\n",
    "model = Word2Vec(sentences=term_list, vector_size=config['vector_size'], window=config['window'], min_count=config['min_count'], workers=config['n_worker'], epochs=config['epochs'], seed=config['seed'])\n",
    "model.save('./Word2Vec/models/w2v_x250.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load('./Word2Vec/models/w2v_x250.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('微軟', 0.7384185791015625),\n",
       " ('谷歌', 0.7303401827812195),\n",
       " ('沃爾瑪', 0.7271144986152649),\n",
       " ('Amazon', 0.6968547105789185),\n",
       " ('Meta', 0.6739716529846191),\n",
       " ('Alphabet', 0.6320428848266602),\n",
       " ('蘋果', 0.6058663129806519),\n",
       " ('Amazon.com', 0.6026239991188049),\n",
       " ('AMZN-US', 0.6015448570251465),\n",
       " ('Salesforce', 0.5936291217803955),\n",
       " ('網飛', 0.59291672706604),\n",
       " ('亞馬', 0.5921523571014404),\n",
       " ('特斯拉', 0.5883162021636963),\n",
       " ('Shopify', 0.5848883390426636),\n",
       " ('AMZN.US', 0.5843936204910278),\n",
       " ('WMT-US', 0.5803993344306946),\n",
       " ('eBay', 0.5784863829612732),\n",
       " ('Etsy', 0.5702493190765381),\n",
       " ('WMT', 0.5666285157203674),\n",
       " ('Wayfair', 0.5599676966667175)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('亞馬遜', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocVec(model, docterms: list, vec_size: int):\n",
    "        docVec = np.zeros(vec_size)\n",
    "        for term in docterms:\n",
    "                try:\n",
    "                        docVec += model.wv.get_vector(term)\n",
    "                except:\n",
    "                        continue\n",
    "        return docVec/len(docterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3259768 , -0.08963934, -1.4230092 , -0.4584967 , -1.7671663 ,\n",
       "       -3.1347213 ,  1.1926342 , -0.7425937 , -1.0004174 ,  1.6443976 ,\n",
       "        0.48187158,  1.9733016 , -1.2037859 , -0.5133991 , -0.76947707,\n",
       "       -0.6595584 ,  0.6938867 , -0.15623398, -0.8099868 ,  1.1948383 ,\n",
       "        0.35275993, -0.9776071 ,  1.8301219 ,  3.4803278 , -2.65332   ,\n",
       "        2.0755057 , -2.1783483 ,  0.6475265 ,  3.4772117 ,  2.0485702 ,\n",
       "        1.4591857 ,  2.0045247 , -1.3418661 , -1.2149343 ,  0.82482696,\n",
       "       -1.1021904 ,  2.130905  , -0.2452097 , -1.8463897 , -0.5720847 ,\n",
       "       -1.0489285 , -0.06834292,  0.2727784 ,  1.1981541 ,  1.3986541 ,\n",
       "       -1.9536257 , -0.5904816 , -2.1405096 , -0.90886116,  3.7766573 ,\n",
       "       -1.1811665 , -1.5931613 , -1.7466832 ,  1.173405  , -1.3575096 ,\n",
       "        0.95159423, -1.4727118 , -1.6144832 ,  0.11106312,  2.7539542 ,\n",
       "       -0.47196868,  1.0432031 , -0.88143045, -1.3062166 ,  0.5475294 ,\n",
       "        1.3616416 , -1.9597993 ,  0.01964836,  0.3398393 ,  1.6574284 ,\n",
       "       -1.2321745 , -1.5457718 , -1.0917542 ,  0.208118  , -1.8834429 ,\n",
       "       -1.2849396 , -0.44688708, -1.9178592 ,  1.9874991 ,  0.41150352,\n",
       "        1.4718927 , -1.3414696 , -0.39585283, -1.6292262 ,  2.0614135 ,\n",
       "       -1.9546483 , -2.7133293 , -2.0367625 ,  0.6832311 ,  2.02434   ,\n",
       "       -0.31759042, -0.12468871, -2.5467618 ,  1.0397824 , -3.0906675 ,\n",
       "        0.97438604, -0.42783016,  0.92037624,  2.379862  , -1.4812427 ,\n",
       "        0.9275569 , -1.1254271 ,  0.91684145,  2.6092627 , -0.27599365,\n",
       "        0.6552967 , -1.8293287 , -3.2154958 , -2.945575  ,  2.0814486 ,\n",
       "       -1.866467  ,  1.6873205 ,  0.45756695,  2.088228  ,  1.2248374 ,\n",
       "       -0.27992842, -0.9582858 , -2.5778115 ,  4.222765  ,  0.49357206,\n",
       "       -0.05371311, -1.3889135 , -3.8145628 ,  0.84523416,  0.6503562 ,\n",
       "       -0.59867096,  2.8291492 ,  0.7158635 , -0.01607589, -2.2056522 ,\n",
       "       -1.7326669 ,  1.610723  ,  0.23581658,  1.1706109 ,  1.8367596 ,\n",
       "        3.8163366 , -3.626215  ,  0.7462881 ,  0.47276896,  1.3975309 ,\n",
       "        1.4217889 ,  1.989706  , -1.9150815 ,  2.615617  , -2.1263824 ,\n",
       "       -1.2888298 ,  0.9218522 , -3.7933753 ,  0.6088224 , -0.5055103 ,\n",
       "        3.330047  ,  0.03455605,  3.1148899 ,  0.23173063, -0.02800469,\n",
       "        0.25371456, -0.26412448, -2.2635353 , -1.4383373 , -1.2431202 ,\n",
       "        1.2495292 ,  1.3297325 , -4.3370366 ,  3.0449805 ,  1.0048765 ,\n",
       "       -0.27204752,  2.0613437 , -0.20905493, -0.78393805, -2.9408069 ,\n",
       "       -0.56110597,  0.8806603 ,  0.6389728 ,  0.09892857,  0.22874938,\n",
       "        0.44028154,  1.5519795 , -1.2332504 ,  0.77898395,  1.5580089 ,\n",
       "        2.4799864 ,  3.0635674 ,  1.229852  ,  1.1589998 , -0.5459261 ,\n",
       "        1.2109836 ,  0.1399534 , -3.1462672 , -0.7232388 ,  1.1831046 ,\n",
       "       -0.05165362, -0.75774336,  0.8641203 , -1.3598614 , -1.7151228 ,\n",
       "       -1.2755785 , -0.4046897 , -0.17638102,  0.26017913, -2.4774532 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.get_vector('輝達')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./mid-term/terms_data/2603長榮_tfidf_down.csv', newline='', encoding='utf-8')\n",
    "terms = csv.reader(f, delimiter=',')\n",
    "test_list = list()\n",
    "i=0\n",
    "for term in terms:\n",
    "    i+=1\n",
    "    if i>1:\n",
    "        test_list.append(term[0])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eeb02\\.virtualenvs\\HW2-PfLazmZH\\lib\\site-packages\\scipy\\spatial\\distance.py:622: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BVector = getDocVec(w2v, test_list, 200)\n",
    "wordvec1 = getDocVec(w2v, ['美股'], 200)\n",
    "wordvec2 = getDocVec(w2v, ['亞馬遜'], 200)\n",
    "similarity = cosine(wordvec1, wordvec2)\n",
    "similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('./terms_data/mid_news_OK.csv', delimiter=',', encoding='utf-8')\n",
    "bbs_df = pd.read_csv('./terms_data/mid_bbs_OK.csv', delimiter=',', encoding='utf-8')\n",
    "forum_df = pd.read_csv('./terms_data/mid_forum_OK.csv', delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_time</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>財政部 內政部 一站式 服務 動產 移轉 登記 搞定 避免 民眾 辦理 動產 買賣 移轉 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>IMF 美元 全球 外匯 儲備 比重 新高 週二 31 國際貨幣組織 公布 IMF 數據 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>騰訊集團 34億 美元 收購 環球 音樂 10 股權 外電 報導 騰訊集團 0700 HK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>加幣 漲幅 勇冠 10 瑞信 央行 政策 明年 主要 風險 週二 31 受到 中國 強勁 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>股盤 收低 中央社 台北 2020年 1月 1日 歐洲 股市 今年 最後 交易日 交易 清...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230605</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>友達 ❷❺ 元以 蘇起 不知 多少 老是 說話</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230606</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>長期 投資人 ETF 超額 報酬 建議 巴菲特 2013年 股東信 提出 建議 一般人 不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230607</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>美國 台積電 美國 設廠 不會 影響 美國 台灣 安全 承諾 晶片 中國 打掉 台灣 之後...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230608</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>快笑死 根本 指標 AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230609</th>\n",
       "      <td>2023-03-21</td>\n",
       "      <td>AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉 預測 短期 一日 行情 甚麼 意...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_time                                            content\n",
       "0        2020-01-01   財政部 內政部 一站式 服務 動產 移轉 登記 搞定 避免 民眾 辦理 動產 買賣 移轉 ...\n",
       "1        2020-01-01   IMF 美元 全球 外匯 儲備 比重 新高 週二 31 國際貨幣組織 公布 IMF 數據 ...\n",
       "2        2020-01-01   騰訊集團 34億 美元 收購 環球 音樂 10 股權 外電 報導 騰訊集團 0700 HK...\n",
       "3        2020-01-01   加幣 漲幅 勇冠 10 瑞信 央行 政策 明年 主要 風險 週二 31 受到 中國 強勁 ...\n",
       "4        2020-01-01   股盤 收低 中央社 台北 2020年 1月 1日 歐洲 股市 今年 最後 交易日 交易 清...\n",
       "...             ...                                                ...\n",
       "1230605  2023-03-21                           友達 ❷❺ 元以 蘇起 不知 多少 老是 說話\n",
       "1230606  2023-03-21   長期 投資人 ETF 超額 報酬 建議 巴菲特 2013年 股東信 提出 建議 一般人 不...\n",
       "1230607  2023-03-21   美國 台積電 美國 設廠 不會 影響 美國 台灣 安全 承諾 晶片 中國 打掉 台灣 之後...\n",
       "1230608  2023-03-21             快笑死 根本 指標 AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉\n",
       "1230609  2023-03-21   AI 股票 AI 解說 股市 重大 事件 矽谷銀行 倒閉 預測 短期 一日 行情 甚麼 意...\n",
       "\n",
       "[1230610 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_df = pd.concat([news_df, bbs_df, forum_df], ignore_index=True)\n",
    "term_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del news_df, bbs_df, forum_df\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doc2Vec模型的訓練資料集格式為 [sentence, tag]，使用TaggedDocument來包裝資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TagDoc = gensim.models.doc2vec.TaggedDocument\n",
    "\n",
    "def tagTrainSet(sentences):\n",
    "    train_set = []\n",
    "    for i, text in enumerate(sentences):\n",
    "        try:\n",
    "            word_list = text.split(' ')\n",
    "        except:\n",
    "            word_list = str(text).split(' ')\n",
    "\n",
    "        l = len(word_list)\n",
    "        word_list[l-1] = word_list[l-1].strip()\n",
    "        doc = TagDoc(word_list, tags=[i])\n",
    "        train_set.append(doc)\n",
    "    \n",
    "    return train_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, vec_size):\n",
    "    model = Doc2Vec(train_data, min_count=1, window=3, vector_size=vec_size, sample=1e-3, negative=5, workers=4)\n",
    "    model.train(train_data, total_examples=model.corpus_count, epochs=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = tagTrainSet(term_df['content'])\n",
    "\n",
    "for i in range(5):\n",
    "    print(trainSet[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = train(trainSet, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.save('./Word2Vec/D2V_models/d2v_x250.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW2-PfLazmZH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
